% This code is used to generate all the figures in Chapter 2.1
% In an attempt to explain our computational modelling rationale
% ~Koen Frolichs
%% 2.1.1.1 The Rescorla-Wagner learning rule
% Setting up the simple conditioning example
alpha       = .05; % Learning rate
% expec_t1    = 0;   % The dog expects no food at the beginning
timesteps   = 10;  % The number of trials in the experiment
reward      = 1;   % The dog will always be rewarded
expec_time  = zeros(1,timesteps); % To keep track of the dog's expectation over time
                                  % Starts with no expectation i.e., 0

% Create two anonymous functions to do the calculations
calcPE  = @(expectation, outcome) outcome - expectation; % To calculate the Prediction Error
RW_rule = @(expectation, PE, learning_rate) expectation + PE * learning_rate; % To calculate the RW updating

for iT = 1:timesteps
    expec_time(iT
    
end


%% 2.1.1.2 Increasing the complexity of the models

%% 2.1.1.3 Applying the model to real data

%% 2.1.1.4 Model Checks